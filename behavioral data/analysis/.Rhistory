str_remove_all("^assistant *") %>% str_replace_all("\\/|\\.", "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n") %>%
str_remove_all("^assistant *") %>% str_replace_all("\\/|\\.[]", "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n") %>%
str_remove_all("^assistant *") %>% str_replace_all("\\/|\\.\\[\\]", "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n") %>%
str_remove_all("^assistant *") %>% str_replace_all("\\/|\\.\[\]", "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n") %>%
str_remove_all("^assistant *") %>% str_replace_all("\\/|\\.\\[\\]", "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n") %>%
str_remove_all("^assistant *") %>% str_replace_all('\\/|\\.|\\[|\\]|\\|"', "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n") %>%
str_remove_all("^assistant *") %>% str_replace_all('\\/|\\.|\\[|\\]|\\|\\"', "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n") %>%
str_remove_all("^assistant *") %>% str_replace_all('\\/|\\.|\\[|\\]|\\|"', "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n") %>%
str_remove_all("^assistant *") %>% str_replace_all('\\/|\\.|\\[|\\]|\\|\\"', "")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all("\n|\\/|\\.|\\[|\\]|\\") %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]|\\|"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]|\\|\\"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
llama_dict = noquote(tolower(llama_resp)) %>% str_remove_all('\n|\\/|\\.|\\[|\\]|\\') %>%
str_remove_all("^assistant *")
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]|\\') %>%
str_remove_all("^assistant *")
llama_dict = noquotes(tolower(llama_resp)) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
llama_dict = noquote(tolower(llama_resp)) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
df_long = read_csv("1_data/loss_semantics_clean.csv") %>%
pivot_longer(
cols = association_1:situation_5,
names_to = c(".value", "position"),
names_pattern = "(association|situation)(_\\d+)") %>%
mutate(position = str_remove(position, "_") %>% as.integer()) %>%
mutate(association = case_when(tolower(association) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ association),
situation = case_when(tolower(situation) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ situation),
association = str_replace_all(association, "/", " or "),
situation = str_replace_all(situation, "/", " or "))
entries = unique(df_long$association)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant who accurately suggests correct spellings for English words in the context of a free association task. The free association task presents cue 'loss' and asks participants to produce free association responses."
instruct = "What is the correct English spelling for '{WORD}' in the context of the cue 'loss'. The spelling could be false or correct. Choose an appropriate capitalization. Only return the correct spelling for '{WORD}' and use the following format: [correct spelling]."
candidates = entries_clean[!correct]
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean =dict[df_long$association]
write_csv(df_long, "1_data/loss_semantics_clean_spellcheck.csv")
View(df_long)
df_long = read_csv("1_data/loss_semantics_clean.csv") %>%
pivot_longer(
cols = association_1:situation_5,
names_to = c(".value", "position"),
names_pattern = "(association|situation)(_\\d+)") %>%
mutate(position = str_remove(position, "_") %>% as.integer()) %>%
mutate(association = case_when(tolower(association) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ association),
situation = case_when(tolower(situation) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ situation),
association = str_replace_all(association, "/", " or "),
situation = str_replace_all(situation, "/", " or "))
# CLEANUP ASSOCIATIONS
entries = unique(df_long$association)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant who accurately suggests correct spellings for English words in the context of a free association task. The free association task presents cue 'loss' and asks participants to produce free association responses."
instruct = "What is the correct English spelling for '{WORD}' in the context of the cue 'loss'. The spelling could be false or correct. Choose an appropriate capitalization. Only return the correct spelling for '{WORD}' and use the following format: [correct spelling]."
candidates = entries_clean[!correct]
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean = dict[df_long$association]
# CLEANUP SITUATIONS
entries = unique(df_long$situation)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant who accurately suggests correct spellings for English words in the context of a situation retrieval task. The situation retrieval task asks participants to produce situations related to loss."
instruct = "What is the correct English spelling for '{WORD}' in the context loss-related situations. The spelling could be false or correct. Choose an appropriate capitalization. Only return the correct spelling for '{WORD}' and use the following format: [correct spelling]."
candidates = entries_clean[!correct]
print(length(entries_clean[!correct]))
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$situation_clean = dict[df_long$situation]
write_csv(df_long, "1_data/loss_semantics_clean_spellcheck.csv")
entries = unique(df_long$association)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
length(entries_clean[!correct])
entries = unique(df_long$association_clean)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
length(entries_clean[!correct])
(entries_clean[!correct])
entries = unique(df_long$situation)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
length(entries_clean[!correct])
entries = unique(df_long$situation_clean)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
length(entries_clean[!correct])
(entries_clean[!correct])
length(entries_clean[!correct])
write_csv(df_long, "1_data/loss_semantics_clean_spellcheck.csv")
df_exp = read_csv("1_data/loss_semantics_clean_spellcheck_normalized.csv")
View(df_exp)
library(tidyverse)
source("2_code/_helpers.R")
library(tidyverse)
source("2_code/_helpers.R")
df_long = read_csv("1_data/loss_semantics_clean.csv") %>%
pivot_longer(
cols = association_1:situation_5,
names_to = c(".value", "position"),
names_pattern = "(association|situation)(_\\d+)") %>%
mutate(position = str_remove(position, "_") %>% as.integer()) %>%
mutate(association = case_when(tolower(association) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ association),
situation = case_when(tolower(situation) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ situation),
association = str_replace_all(association, "/", " or "),
situation = str_replace_all(situation, "/", " or "))
entries = unique(df_long$association)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant who accurately suggests correct spellings for English words in the context of a free association task. The free association task presents cue 'loss' and asks participants to produce free association responses."
instruct = "What is the correct English spelling for '{WORD}' in the context of the cue 'loss'. The spelling could be false or correct. Choose an appropriate capitalization. Only return the correct spelling for '{WORD}' and use the following format: [correct spelling]."
candidates = entries_clean[!correct]
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
source("~/Mi unidad/Universidad/doctorado/experiments/loss semantics/exp/analysis/2_code/_helpers.R")
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
source("~/Mi unidad/Universidad/doctorado/experiments/loss semantics/exp/analysis/2_code/_helpers.R")
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
source("~/Mi unidad/Universidad/doctorado/experiments/loss semantics/exp/analysis/2_code/_helpers.R")
?er_embed
require(embedR)
?er_embed
require(tidyverse)
require(embedR)
library(cluster)
source("2_code/_helpers.R")
library(ggplot2)
library(factoextra)
library(wordcloud2)
library(tidytext)
library(viridisLite)
set.seed(123)
df_exp = read_csv("1_data/loss_semantics_clean_spellcheck_normalized.csv")
# Reshape the data from wide to long format
df_exp <- df_exp %>%
pivot_longer(cols = c(association, situation),
names_to = "type",
values_to = "word") %>%
pivot_longer(cols = c(association_clean, situation_clean),
names_to = "type_clean",
values_to = "word_clean") %>%
pivot_longer(cols = c(association_clean_normalized, situation_clean_normalized),
names_to = "type_clean_normalized",
values_to = "word_clean_normalized") %>%
filter((type == "association" & type_clean == "association_clean" & type_clean_normalized == "association_clean_normalized") |
(type == "situation" & type_clean == "situation_clean" & type_clean_normalized == "situation_clean_normalized")) %>%
select(-c(type_clean, type_clean_normalized)) %>%
arrange(prolific_id, type)
df_papers = read_csv("../../literature review/1_data/selected_papers_normalized.csv")
er_set_tokens(huggingface = "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", hard = TRUE)
read = T
if (read) {
reticulate::use_virtualenv("pacmap")
embed = readRDS("loss_semantics_embed_papers_exp.RDS")
groups = readRDS("loss_semantics_groups_97_papers_exp.RDS")
} else{
elements = (c(df_exp$word_clean_normalized, df_papers$normalized))
embed = er_embed(elements, api = "huggingface", model = "WhereIsAI/UAE-Large-V1")
saveRDS(embed, "loss_semantics_embed_papers_exp.RDS")
groups = embed %>% er_group(method = "fuzzy", threshold = .97)
saveRDS(groups, "loss_semantics_groups_97_papers_exp.RDS")
}
View(groups)
# umap dimensional reduction
proj = groups |> er_project(method = "umap", k = 2)
# 8 clusters
clust = proj |> er_cluster(method = "hclust", k = 8, verbose = T)
loss = er_frame(clust)
View(loss)
loss %>%
mutate(most_frequent = sapply(group_texts, function(x) x %>% str_to_lower() %>% table() %>% sort(decreasing = T) %>% `[`(1) %>% names()))
loss = loss %>%
mutate(most_frequent = sapply(group_texts, function(x) x %>% str_to_lower() %>% table() %>% sort(decreasing = T) %>% `[`(1) %>% names()))
View(loss)
loss = loss %>%
mutate(cluster_name = case_when(
cluster == 1 ~ "Competitive Failure",
cluster == 2 ~ "Financial",
cluster == 3 ~ "Deprivation",
cluster == 4 ~ "Emotional Turmoil",
cluster == 5 ~ "Career and Life Setbacks",
cluster == 6 ~ "Detriment",
cluster == 7 ~ "Separation",
cluster == 8 ~ "Separation",
TRUE ~ NA))
words_df = loss %>%
unnest(group_texts) %>%
rename(word = group_texts) %>%
group_by(word) %>%
summarise(text=unique(text),
cluster=unique(cluster),
cluster_name=unique(cluster_name),
frequency=n(),
group_dim_1 = unique(dim_1),
group_dim_2 = unique(dim_2)) %>%
mutate(orig = case_when(word %in% df_papers$normalized ~ "Papers",
TRUE ~ "Experiment"))
View(words_df)
View(loss)
words_df = loss %>%
unnest(group_texts) %>%
rename(word = group_texts) %>%
group_by(word) %>%
summarise(text=unique(text),
cluster=unique(cluster),
cluster_name=unique(cluster_name),
frequency=n(),
group_dim_1 = unique(dim_1),
group_dim_2 = unique(dim_2)) %>%
mutate(orig = case_when(word %in% df_papers$normalized ~ "Papers",
word %in% df_papers$normalized & word %in% df_exp$word_clean_normalized ~ "Both",
TRUE ~ "Experiment"))
summary(as.factor(words_df$orig))
df_papers$normalized %in% df_exp$word_clean_normalized
sum(df_papers$normalized %in% df_exp$word_clean_normalized)
source("2_code/_helpers.R")
library(tidyverse)
source("2_code/_helpers.R")
source("2_code/_helpers.R")
df_long = read_csv("1_data/loss_semantics_clean.csv") %>%
pivot_longer(
cols = association_1:situation_5,
names_to = c(".value", "position"),
names_pattern = "(association|situation)(_\\d+)") %>%
mutate(position = str_remove(position, "_") %>% as.integer()) %>%
mutate(association = case_when(tolower(association) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ association),
situation = case_when(tolower(situation) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ situation),
association = str_replace_all(association, "/", " or "),
situation = str_replace_all(situation, "/", " or "))
entries = unique(df_long$association)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant that provides the correct English spellings in the context of a free association task. In the task, participants were presented with the cues  'loss', 'losing', or 'losses' and were asked to produce five association responses. Your goal is to ensure accurate spelling of the given association."
instruct = "Given the context of the cue 'loss', 'losing', or 'losses', determine the correct English spelling for '{WORD}'. The word may be correctly or incorrectly spelled. Choose the appropriate capitalization. Respond only with the correct spelling for '{WORD}' in this format: [correct spelling]."
candidates = entries_clean[!correct]
print(length(candidates))
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean = dict[df_long$association]
entries = unique(df_long$association_clean)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
candidates = entries_clean[!correct]
print(length(candidates))
candidates
df_long = read_csv("1_data/loss_semantics_clean.csv") %>%
pivot_longer(
cols = association_1:situation_5,
names_to = c(".value", "position"),
names_pattern = "(association|situation)(_\\d+)") %>%
mutate(position = str_remove(position, "_") %>% as.integer()) %>%
mutate(association = case_when(tolower(association) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ association),
situation = case_when(tolower(situation) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ situation),
association = str_replace_all(association, "/", " or "),
situation = str_replace_all(situation, "/", " or "))
entries = unique(df_long$association)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant that provides the correct English spellings in the context of a free association task. In the task, participants were presented with the cues  'loss', 'losing', or 'losses' and were asked to produce five association responses. Your goal is to ensure accurate spelling of the given association."
instruct = "Given the context of the cue 'loss', 'losing', or 'losses', determine the correct English spelling for '{WORD}'. The word may be correctly or incorrectly spelled. Choose the appropriate capitalization. Respond only with the correct spelling for '{WORD}' in this format: [correct spelling]."
candidates = entries_clean[!correct]
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean = dict[df_long$association]
entries = unique(df_long$association_clean)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
candidates = entries_clean[!correct]
print(length(candidates))
candidates
entries = unique(df_long$situation)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant that provides the correct English spellings for words in the context of a situation retrieval task. In the task, participants were asked to recall situations where they have experienced a loss. Your goal is to ensure accurate spelling for the given situation."
instruct = "In the context of loss-related situations, determine the correct English spelling for '{WORD}'. The word may be correctly or incorrectly spelled. Choose the appropriate capitalization. Respond only with the correct spelling for '{WORD}' in this format: [correct spelling]."
candidates = entries_clean[!correct]
print(length(entries_clean[!correct]))
candidates
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
df_long = read_csv("1_data/loss_semantics_clean.csv") %>%
pivot_longer(
cols = association_1:situation_5,
names_to = c(".value", "position"),
names_pattern = "(association|situation)(_\\d+)") %>%
mutate(position = str_remove(position, "_") %>% as.integer()) %>%
mutate(association = case_when(tolower(association) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ association),
situation = case_when(tolower(situation) %in% c("na", "n/a", "none", "no", "nan") ~ NA,
TRUE ~ situation),
association = str_replace_all(association, "/", " or "),
situation = str_replace_all(situation, "/", " or "))
entries = unique(df_long$association)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant that provides the correct English spellings in the context of a free association task. In the task, participants were presented with the cues  'loss', 'losing', or 'losses' and were asked to produce five association responses. Your goal is to ensure accurate spelling of the given association."
instruct = "Given the context of the cue 'loss', 'losing', or 'losses', determine the correct English spelling for '{WORD}' preserving the original phrase. The word may be correctly or incorrectly spelled. Choose the appropriate capitalization. Respond only with the correct spelling for '{WORD}' in this format: [correct spelling]."
candidates = entries_clean[!correct]
print(length(candidates))
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$association_clean = dict[df_long$association]
entries = unique(df_long$situation)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
system = "You are a helpful assistant that provides the correct English spellings for words in the context of a situation retrieval task. In the task, participants were asked to recall situations where they have experienced a loss. Your goal is to ensure accurate spelling for the given situation."
instruct = "In the context of loss-related situations, determine the correct English spelling for '{WORD}' preserving the original phrase. The word may be correctly or incorrectly spelled. Choose the appropriate capitalization. Respond only with the correct spelling for '{WORD}' in this format: [correct spelling]."
candidates = entries_clean[!correct]
print(length(entries_clean[!correct]))
llama_resp = correct_llama(candidates, sleep = .1, system = system, instruct = instruct)
llama_dict = tolower(llama_resp) %>% str_remove_all('\n|\\/|\\.|\\[|\\]"') %>%
str_remove_all("^assistant *")
names(llama_dict) = entries[!correct]
dict = tibble(entries, hunspell = correct) %>%
mutate(correct = case_when(
correct ~ entries,
TRUE ~ llama_dict[entries])) %>%
pull(correct, entries)
df_long$situation_clean = dict[df_long$situation]
entries = unique(df_long$association)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
candidates = entries_clean[!correct]
print(length(candidates))
entries = unique(df_long$association_clean)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
candidates = entries_clean[!correct]
print(length(candidates))
candidates
entries = unique(df_long$situation)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
candidates = entries_clean[!correct]
print(length(entries_clean[!correct]))
entries = unique(df_long$situation_clean)
entries_clean = entries %>% sapply(clean_up) %>% unname()
correct = sapply(entries_clean, check_multi)
candidates = entries_clean[!correct]
print(length(entries_clean[!correct]))
candidates
write_csv(df_long, "1_data/loss_semantics_clean_spellcheck.csv")
library(tidyverse)
source("2_code/_helpers.R")
df = read_csv("1_data/loss_semantics_clean_spellcheck.csv")
# Situations
entries = unique(df$situation_clean)
correct = sapply(entries,
function(x) length(unlist(strsplit(x, split = " "))) < 4)
df = read_csv("1_data/loss_semantics_clean_spellcheck.csv")
# Associations
entries = unique(df$association_clean)
short_responses = sapply(entries,
function(x) length(unlist(strsplit(x, split = " "))) < 1)
candidates = entries[!short_responses]
candidates
short_responses = sapply(entries,
function(x) length(unlist(strsplit(x, split = " "))) < 2)
candidates = entries[!short_responses]
candidates
